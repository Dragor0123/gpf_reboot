#!/usr/bin/env python3
"""
ë‹¨ê³„ë³„ í•™ìŠµ ê³¼ì • ë””ë²„ê¹…
CUDA Index Out of Bounds ì •í™•í•œ ë°œìƒ ì§€ì  ì¶”ì 
"""

import torch
import logging
from pathlib import Path
import os

# CUDA ë””ë²„ê¹… í™œì„±í™”
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'

from utils import (
    set_seed, get_device, load_config,
    setup_logging, log_experiment_info
)
from models import create_model, Classifier
from datasets import load_dataset
from prompts.prompt_function import GPFPrompt
from losses import TargetCentricLoss


def safe_tensor_info(tensor, name):
    """ì•ˆì „í•œ í…ì„œ ì •ë³´ ì¶œë ¥"""
    if tensor is None:
        print(f"âŒ {name}: None")
        return False
    
    try:
        print(f"ğŸ” {name}:")
        print(f"   Shape: {tensor.shape}")
        print(f"   Device: {tensor.device}")
        print(f"   Dtype: {tensor.dtype}")
        
        if tensor.numel() > 0:
            print(f"   Range: [{tensor.min().item():.4f}, {tensor.max().item():.4f}]")
            print(f"   Has NaN: {torch.isnan(tensor).any().item()}")
            print(f"   Has Inf: {torch.isinf(tensor).any().item()}")
        
        return True
    except Exception as e:
        print(f"âŒ Error inspecting {name}: {e}")
        return False


def debug_pretraining_step():
    """Pre-training ë‹¨ê³„ ë””ë²„ê¹…"""
    print("\n" + "="*80)
    print("ğŸ” DEBUGGING PRE-TRAINING STEP")
    print("="*80)
    
    # Config ë¡œë“œ
    config = load_config("config.yaml")
    set_seed(config['experiment']['seed'])
    device = get_device(config['experiment']['device'])
    
    print(f"Device: {device}")
    print(f"Source dataset: {config['experiment']['source_dataset']}")
    print(f"Target dataset: {config['experiment']['target_dataset']}")
    
    try:
        # Source ë°ì´í„° ë¡œë“œ
        print("\nğŸ” Loading source dataset...")
        (source_info, target_info, source_loader, _, _, _, 
         source_svd_reducer) = load_dataset(config)
        
        source_data = next(iter(source_loader))
        source_data = source_data.to(device)
        
        print(f"âœ… Source data loaded successfully")
        safe_tensor_info(source_data.x, "Source features")
        safe_tensor_info(source_data.edge_index, "Source edge_index")
        
        # Edge index ê²€ì¦
        num_nodes = source_data.x.size(0)
        edge_max = source_data.edge_index.max().item() if source_data.edge_index.numel() > 0 else -1
        edge_min = source_data.edge_index.min().item() if source_data.edge_index.numel() > 0 else -1
        
        print(f"ğŸ” Source edge validation:")
        print(f"   Num nodes: {num_nodes}")
        print(f"   Edge range: [{edge_min}, {edge_max}]")
        print(f"   Valid: {edge_max < num_nodes and edge_min >= 0}")
        
        if edge_max >= num_nodes:
            print(f"âŒ FOUND ISSUE: Edge index {edge_max} >= num_nodes {num_nodes}")
            return False
        
        # ê°„ë‹¨í•œ ëª¨ë¸ ìƒì„± ë° í…ŒìŠ¤íŠ¸
        print(f"\nğŸ” Testing model creation...")
        encoder = create_model(
            model_type=config['model']['type'],
            input_dim=source_info['num_features'],
            hidden_dim=config['model']['hidden_dim'],
            num_layers=config['model']['num_layers'],
            dropout=config['model']['dropout']
        ).to(device)
        
        print(f"âœ… Model created successfully")
        
        # Forward pass í…ŒìŠ¤íŠ¸
        print(f"\nğŸ” Testing forward pass...")
        encoder.eval()
        
        with torch.no_grad():
            try:
                h = encoder(source_data.x, source_data.edge_index)
                safe_tensor_info(h, "Encoder output")
                print(f"âœ… Forward pass successful")
                return True
            except RuntimeError as e:
                print(f"âŒ Forward pass failed: {e}")
                return False
        
    except Exception as e:
        print(f"âŒ Pre-training debug failed: {e}")
        return False


def debug_prompt_tuning_step():
    """Prompt tuning ë‹¨ê³„ ë””ë²„ê¹…"""
    print("\n" + "="*80)
    print("ğŸ” DEBUGGING PROMPT TUNING STEP")
    print("="*80)
    
    # Config ë¡œë“œ
    config = load_config("config.yaml")
    set_seed(config['experiment']['seed'])
    device = get_device(config['experiment']['device'])
    
    try:
        # Target ë°ì´í„° ë¡œë“œ
        print("\nğŸ” Loading target dataset...")
        (source_info, target_info, source_loader, target_train_loader, 
         target_val_loader, target_test_loader, source_svd_reducer) = load_dataset(config)
        
        target_data = next(iter(target_train_loader))
        target_data = target_data.to(device)
        
        print(f"âœ… Target data loaded successfully")
        safe_tensor_info(target_data.x, "Target features")
        safe_tensor_info(target_data.edge_index, "Target edge_index")
        
        # Edge index ê²€ì¦
        num_nodes = target_data.x.size(0)
        edge_max = target_data.edge_index.max().item() if target_data.edge_index.numel() > 0 else -1
        edge_min = target_data.edge_index.min().item() if target_data.edge_index.numel() > 0 else -1
        
        print(f"ğŸ” Target edge validation:")
        print(f"   Num nodes: {num_nodes}")
        print(f"   Edge range: [{edge_min}, {edge_max}]")
        print(f"   Valid: {edge_max < num_nodes and edge_min >= 0}")
        
        if edge_max >= num_nodes:
            print(f"âŒ FOUND ISSUE: Edge index {edge_max} >= num_nodes {num_nodes}")
            return False
        
        # Encoder ë¡œë“œ
        source_dataset = config['experiment']['source_dataset']
        checkpoint_path = f"checkpoints/{source_dataset}_encoder_final.pt"
        
        if not Path(checkpoint_path).exists():
            print(f"âŒ Checkpoint not found: {checkpoint_path}")
            print("   Run pre-training first!")
            return False
        
        print(f"ğŸ” Loading encoder from: {checkpoint_path}")
        
        encoder = create_model(
            model_type=config['model']['type'],
            input_dim=target_info['num_features'],
            hidden_dim=config['model']['hidden_dim'],
            num_layers=config['model']['num_layers'],
            dropout=config['model']['dropout']
        ).to(device)
        
        # Checkpoint ë¡œë“œ
        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
        encoder.load_state_dict(checkpoint['model_state_dict'], strict=True)
        encoder.eval()
        
        print(f"âœ… Encoder loaded successfully")
        
        # Prompt ìƒì„±
        print(f"\nğŸ” Creating prompt...")
        prompt = GPFPrompt(
            input_dim=target_info['num_features'],
            p_num=config['prompt']['num_prompts']
        ).to(device)
        
        print(f"âœ… Prompt created successfully")
        
        # Classifier ìƒì„±
        classifier = Classifier(
            input_dim=config['model']['hidden_dim'],
            num_classes=target_info['num_classes']
        ).to(device)
        
        print(f"âœ… Classifier created successfully")
        
        # Step-by-step forward pass
        print(f"\nğŸ” Step-by-step forward pass...")
        
        x = target_data.x
        edge_index = target_data.edge_index
        
        # Step 1: Prompt
        print(f"Step 1: Applying prompt...")
        safe_tensor_info(x, "Input features")
        
        try:
            prompted_x = prompt.add(x)
            safe_tensor_info(prompted_x, "Prompted features")
            print(f"âœ… Prompt applied successfully")
        except Exception as e:
            print(f"âŒ Prompt failed: {e}")
            return False
        
        # Step 2: Encoder
        print(f"Step 2: Encoder forward...")
        safe_tensor_info(prompted_x, "Encoder input")
        safe_tensor_info(edge_index, "Edge index")
        
        try:
            with torch.no_grad():
                h = encoder(prompted_x, edge_index)
            safe_tensor_info(h, "Encoder output")
            print(f"âœ… Encoder forward successful")
        except RuntimeError as e:
            print(f"âŒ Encoder forward failed: {e}")
            print(f"   This is likely where CUDA Index Out of Bounds occurs!")
            
            # ë” ìì„¸í•œ ì •ë³´
            print(f"ğŸ” Detailed debug info:")
            print(f"   Prompted_x shape: {prompted_x.shape}")
            print(f"   Edge_index shape: {edge_index.shape}")
            print(f"   Edge_index device: {edge_index.device}")
            print(f"   Prompted_x device: {prompted_x.device}")
            
            if edge_index.numel() > 0:
                print(f"   Edge_index min: {edge_index.min()}")
                print(f"   Edge_index max: {edge_index.max()}")
                print(f"   Num nodes (from features): {prompted_x.size(0)}")
            
            return False
        
        # Step 3: Classifier
        print(f"Step 3: Classifier forward...")
        
        try:
            logits = classifier(h)
            safe_tensor_info(logits, "Classifier output")
            print(f"âœ… Classifier forward successful")
        except Exception as e:
            print(f"âŒ Classifier failed: {e}")
            return False
        
        print(f"\nâœ… All forward pass steps completed successfully!")
        
        # Target-Centric í…ŒìŠ¤íŠ¸ (ë¬¸ì œê°€ ì—¬ê¸°ì„œ ë°œìƒí•  ìˆ˜ë„ ìˆìŒ)
        if config['target_centric']['enable']:
            print(f"\nğŸ” Testing Target-Centric initialization...")
            
            try:
                loss_fn = TargetCentricLoss(config).to(device)
                loss_fn.initialize_regularizer_with_target_features(
                    target_data.x, encoder, target_data.edge_index
                )
                print(f"âœ… Target-Centric initialized successfully")
            except Exception as e:
                print(f"âŒ Target-Centric failed: {e}")
                return False
        
        return True
        
    except Exception as e:
        print(f"âŒ Prompt tuning debug failed: {e}")
        return False


def main():
    """ì „ì²´ ë””ë²„ê¹… ì‹¤í–‰"""
    print("ğŸš¨ COMPREHENSIVE DEBUGGING SESSION")
    print("Tracking CUDA Index Out of Bounds...")
    
    # 1. Pre-training ë‹¨ê³„ ì²´í¬
    pretrain_ok = debug_pretraining_step()
    
    # 2. Prompt tuning ë‹¨ê³„ ì²´í¬
    prompt_ok = debug_prompt_tuning_step()
    
    print("\n" + "="*80)
    print("ğŸ“‹ DEBUGGING SUMMARY")
    print("="*80)
    print(f"Pre-training step: {'âœ… OK' if pretrain_ok else 'âŒ FAILED'}")
    print(f"Prompt tuning step: {'âœ… OK' if prompt_ok else 'âŒ FAILED'}")
    
    if not pretrain_ok:
        print(f"\nğŸš¨ ISSUE FOUND IN PRE-TRAINING!")
        print("Check source dataset or model creation")
    elif not prompt_ok:
        print(f"\nğŸš¨ ISSUE FOUND IN PROMPT TUNING!")
        print("This is likely where CUDA Index Out of Bounds occurs")
        print("Check target dataset or encoder loading")
    else:
        print(f"\nğŸ¤” Both steps seem OK individually...")
        print("The issue might occur during actual training loop")
        print("Try running with CUDA_LAUNCH_BLOCKING=1 for more details")


if __name__ == "__main__":
    main()