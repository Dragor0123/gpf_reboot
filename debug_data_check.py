#!/usr/bin/env python3
"""
ê¸´ê¸‰ ë°ì´í„° ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
CUDA Index Out of Bounds ì›ì¸ íŒŒì•…
"""

import torch
from datasets.load_dataset import _load_single_dataset, _create_splits
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

def check_dataset_integrity(dataset_name):
    """ë°ì´í„°ì…‹ì˜ edge_index ë¬´ê²°ì„± ê²€ì‚¬"""
    print(f"\n{'='*60}")
    print(f"ğŸ” Checking dataset: {dataset_name}")
    print(f"{'='*60}")
    
    try:
        # ì›ë³¸ ë°ì´í„° ë¡œë“œ
        dataset = _load_single_dataset(dataset_name)
        data = dataset[0]
        
        # ê¸°ë³¸ ì •ë³´
        num_nodes = data.num_nodes
        num_edges = data.num_edges
        num_features = data.num_node_features
        
        print(f"ğŸ“Š Basic Info:")
        print(f"   Nodes: {num_nodes}")
        print(f"   Edges: {num_edges}")
        print(f"   Features: {num_features}")
        
        # Edge index ê²€ì‚¬
        edge_index = data.edge_index
        print(f"\nğŸ” Edge Index Analysis:")
        print(f"   Shape: {edge_index.shape}")
        print(f"   Min value: {edge_index.min().item()}")
        print(f"   Max value: {edge_index.max().item()}")
        print(f"   Valid range: [0, {num_nodes - 1}]")
        
        # ğŸš¨ í•µì‹¬ ì²´í¬: Index Out of Bounds ê²€ì‚¬
        max_node_id = edge_index.max().item()
        min_node_id = edge_index.min().item()
        
        if max_node_id >= num_nodes:
            print(f"âŒ INDEX OUT OF BOUNDS DETECTED!")
            print(f"   Max node ID in edges: {max_node_id}")
            print(f"   But only {num_nodes} nodes exist (0~{num_nodes-1})")
            
            # ë¬¸ì œê°€ ìˆëŠ” edge ê°œìˆ˜ ê³„ì‚°
            invalid_edges = ((edge_index >= num_nodes) | (edge_index < 0)).any(dim=0).sum()
            print(f"   Invalid edges: {invalid_edges.item()}/{num_edges}")
            
            return False
        
        if min_node_id < 0:
            print(f"âŒ NEGATIVE INDEX DETECTED!")
            print(f"   Min node ID: {min_node_id}")
            return False
        
        print(f"âœ… Edge index is valid!")
        
        # Split í›„ì—ë„ ê²€ì‚¬
        print(f"\nğŸ” After Split:")
        data_split = _create_splits(data, val_ratio=0.1, test_ratio=0.2, shuffle=True)
        
        # Split í›„ì—ë„ edge_indexëŠ” ë™ì¼í•´ì•¼ í•¨
        if not torch.equal(data.edge_index, data_split.edge_index):
            print(f"âš ï¸  Edge index changed after split!")
        else:
            print(f"âœ… Edge index unchanged after split")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error loading {dataset_name}: {e}")
        return False


def main():
    """ëª¨ë“  ë°ì´í„°ì…‹ ê²€ì‚¬"""
    datasets = ['cora', 'citeseer', 'pubmed', 'computers', 'photo']
    
    print("ğŸš¨ EMERGENCY DATA INTEGRITY CHECK")
    print("Looking for CUDA Index Out of Bounds causes...")
    
    results = {}
    
    for dataset_name in datasets:
        try:
            is_valid = check_dataset_integrity(dataset_name)
            results[dataset_name] = is_valid
        except Exception as e:
            print(f"âŒ Failed to check {dataset_name}: {e}")
            results[dataset_name] = False
    
    print(f"\n{'='*60}")
    print("ğŸ“‹ SUMMARY")
    print(f"{'='*60}")
    
    for dataset, is_valid in results.items():
        status = "âœ… VALID" if is_valid else "âŒ INVALID"
        print(f"{dataset:>10}: {status}")
    
    # ë¬¸ì œê°€ ìˆëŠ” ë°ì´í„°ì…‹ ì‹ë³„
    invalid_datasets = [name for name, valid in results.items() if not valid]
    
    if invalid_datasets:
        print(f"\nğŸš¨ PROBLEMATIC DATASETS: {invalid_datasets}")
        print("These datasets likely cause CUDA Index Out of Bounds!")
        
        print(f"\nğŸ”§ RECOMMENDED FIXES:")
        print("1. Add edge index cleaning in data loading")
        print("2. Remove invalid edges before training")
        print("3. Check original dataset files")
    else:
        print(f"\nğŸ¤” All datasets seem valid...")
        print("The Index Out of Bounds might be caused by:")
        print("1. Data augmentation (edge dropping)")
        print("2. Graph transformation during training")
        print("3. Device transfer issues")


if __name__ == "__main__":
    main()
    